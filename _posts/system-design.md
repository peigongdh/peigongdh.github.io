## 后端架构技术图谱

一些概念的整理与理解

### bitset 位集

Java平台的BitSet用于存放一个位序列，如果要高效的存放一个位序列，就可以使用位集(BitSet)。由于位集将位包装在字节里，所以使用位集比使用Boolean对象的List更加高效和更加节省存储空间。
BitSet是位操作的对象，值只有0或1即false和true，内部维护了一个long数组，初始只有一个long，所以BitSet最小的size是64，当随着存储的元素越来越多，BitSet内部会动态扩充，一次扩充64位，最终内部是由N个long来存储。
默认情况下，BitSet的所有位都是false即0。

应用场景：
1. 统计一组大数据中没有出现过的数；
将这组数据映射到BitSet，然后遍历BitSet，对应位为0的数表示没有出现过的数据。
2. 对大数据进行排序；
将数据映射到BitSet，遍历BitSet得到的就是有序数据。
3. 在内存对大数据进行压缩存储等等。
一个GB的内存空间可以存储85亿多个数，可以有效实现数据的压缩存储，节省内存空间开销。

注：
1. 当使用大数据排序等场景时bitset的bit数应大于等于最大数
2. 排序无法解决数据重复的问题

### 树

#### 二叉树
每个节点最多有两个叶子节点。

#### 完全二叉树
叶节点只能出现在最下层和次下层，并且最下面一层的结点都集中在该层最左边的若干位置的二叉树。

#### 平衡二叉树
左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。

#### 二叉查找树（BST）
二叉查找树（Binary Search Tree），也称有序二叉树（ordered binary tree）,排序二叉树（sorted binary tree）。

#### 红黑树
添加阶段后，左旋或者右旋从而再次达到平衡。

#### B，B+，B*树
MySQL是基于B+树聚集索引组织表
B+树的叶子节点链表结构相比于 B-树便于扫库，和范围检索。

#### LSM 树
LSM（Log-Structured Merge-Trees）和 B+ 树相比，是牺牲了部分读的性能来换取写的性能(通过批量写入)，实现读写之间的平衡。 Hbase、LevelDB、Tair（Long DB）、nessDB 采用 LSM 树的结构。LSM可以快速建立索引。

TODO: B树等概念的巩固

### 布隆过滤器

常用于大数据的排重，比如email，url 等。 核心原理：将每条数据通过计算产生一个指纹（一个字节或多个字节，但一定比原始数据要少很多），其中每一位都是通过随机计算获得，在将指纹映射到一个大的按位存储的空间中。注意：会有一定的错误率。 优点：空间和时间效率都很高。 缺点：随着存入的元素数量增加，误算率随之增加。

### 事务 ACID 特性

事务的隔离级别
- 未提交读：一个事务可以读取另一个未提交的数据，容易出现脏读的情况。
- 读提交：一个事务等另外一个事务提交之后才可以读取数据，但会出现不可重复读的情况（多次读取的数据不一致），读取过程中出现UPDATE操作，会多。（大多数数据库默认级别是RC，比如SQL Server，Oracle），读取的时候不可以修改。
- 可重复读： 同一个事务里确保每次读取的时候，获得的是同样的数据，但不保障原始数据被其他事务更新（幻读），Mysql InnoDB 就是这个级别。
- 序列化：所有事物串行处理（牺牲了效率）

区分读提交和可重复读：
> https://blog.csdn.net/tolcf/article/details/49311035

读提交：
务A事先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。造成了不可重复读（虚读）。
可重复读：
事务A读取与搜索条件相匹配的若干行。事务B以插入或删除行等方式来修改事务A的结果集，然后再提交。事务A再读取时，却发现数据发生了变化。造成了幻读。

很多人都容易混淆不可重复读和幻读的概念，当然，本人也是纠结了好久，下面就说一下我的理解。
不可重复读真正含义应该包含虚读和幻读。

- 所谓的虚读，也就是大家经常说的不可重复读，是指在数据库访问中，一个事务范围内两个相同的查询却返回了不同数据。这是由于查询时系统中其他事务修改的提交而引起的。比如事务T1读取某一数据，事务T2读取并修改了该数据，T1为了对读取值进行检验而再次读取该数据，便得到了不同的结果。
一种更易理解的说法是：在一个事务内，多次读同一个数据。在这个事务还没有结束时，另一个事务也访问该同一数据。那么，在第一个事务的两次读数据之间。由于第二个事务的修改，那么第一个事务读到的数据可能不一样，这样就发生了在一个事务内两次读到的数据是不一样的，因此称为不可重复读，即原始读取不可重复。
- 所谓幻读，是指事务A读取与搜索条件相匹配的若干行。事务B以插入或删除行等方式来修改事务A的结果集，然后再提交。
幻读是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，比如这种修改涉及到表中的“全部数据行”。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入“一行新数据”。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样.一般解决幻读的方法是增加范围锁RangeS，锁定检锁范围为只读，这样就避免了幻读。

MVCC
- innodb 中 MVCC 用在 Repeatable-Read 隔离级别。
- MVCC 会产生幻读问题（更新时异常。）
- 通过隐藏版本列来实现 MVCC 控制，一列记录创建时间、一列记录删除时间，这里的时间每次只操作比当前版本小（或等于）的 行。

### 锁

**重点**

#### 公平锁 & 非公平锁

公平锁的作用就是严格按照线程启动的顺序来执行的，不允许其他线程插队执行的；而非公平锁是允许插队的。
默认情况下 ReentrantLock 和 synchronized 都是非公平锁。ReentrantLock 可以设置成公平锁。

#### 乐观锁&悲观锁

- 悲观锁
悲观锁如果使用不当（锁的条数过多），会引起服务大面积等待。推荐优先使用乐观锁+重试。
- 乐观锁的方式：版本号+重试方式
悲观锁：通过 select ... for update 进行行锁(不可读、不可写，share 锁可读不可写)。

> https://www.cnblogs.com/zhiqian-ali/p/6200874.html

悲观锁（Pessimistic Lock）
悲观锁的特点是先获取锁，再进行业务操作，即“悲观”的认为获取锁是非常有可能失败的，因此要先确保获取锁成功再进行业务操作。通常所说的“一锁二查三更新”即指的是使用悲观锁。通常来讲在数据库上的悲观锁需要数据库本身提供支持，即通过常用的select … for update操作来实现悲观锁。当数据库执行select for update时会获取被select中的数据行的行锁，因此其他并发执行的select for update如果试图选中同一行则会发生排斥（需要等待行锁被释放），因此达到锁的效果。select for update获取的行锁会在当前事务结束时自动释放，因此必须在事务中使用。
这里需要注意的一点是不同的数据库对select for update的实现和支持都是有所区别的，例如oracle支持select for update no wait，表示如果拿不到锁立刻报错，而不是等待，mysql就没有no wait这个选项。另外mysql还有个问题是select for update语句执行中所有扫描过的行都会被锁上，这一点很容易造成问题。因此如果在mysql中用悲观锁务必要确定走了索引，而不是全表扫描。

乐观锁（Optimistic Lock）
乐观锁的特点先进行业务操作，不到万不得已不去拿锁。即“乐观”的认为拿锁多半是会成功的，因此在进行完业务操作需要实际更新数据的最后一步再去拿一下锁就好。
乐观锁在数据库上的实现完全是逻辑的，不需要数据库提供特殊的支持。一般的做法是在需要锁的数据上增加一个版本号，或者时间戳，然后按照如下方式实现：
```sql
1. SELECT data AS old_data, version AS old_version FROM …;
2. 根据获取的数据进行业务操作，得到new_data和new_version
3. UPDATE SET data = new_data, version = new_version WHERE version = old_version
if (updated row > 0) {
    // 乐观锁获取成功，操作完成
} else {
    // 乐观锁获取失败，回滚并重试
}
```
乐观锁是否在事务中其实都是无所谓的，其底层机制是这样：在数据库内部update同一行的时候是不允许并发的，即数据库每次执行一条update语句时会获取被update行的写锁，直到这一行被成功更新后才释放。因此在业务操作进行前获取需要锁的数据的当前版本号，然后实际更新数据时再次对比版本号确认与之前获取的相同，并更新版本号，即可确认这之间没有发生并发的修改。如果更新失败即可认为老版本的数据已经被并发修改掉而不存在了，此时认为获取锁失败，需要回滚整个业务操作并可根据需要重试整个过程。

总结：
- 乐观锁在不发生取锁失败的情况下开销比悲观锁小，但是一旦发生失败回滚开销则比较大，因此适合用在取锁失败概率比较小的场景，可以提升系统并发性能
- 乐观锁还适用于一些比较特殊的场景，例如在业务操作过程中无法和数据库保持连接等悲观锁无法适用的地方

#### mysql并发死锁

mysql的innodb存储引擎实务锁虽然是锁行，但它内部是锁索引的。
锁相同数据的不同索引条件可能会引起死锁。

> https://www.cnblogs.com/Lawson/p/5008741.html
> https://www.cnblogs.com/zejin2008/p/5262751.html

#### 乐观锁 & CAS

和MySQL乐观锁方式相似，只不过是通过和原值进行比较。

> https://blog.csdn.net/u011514810/article/details/76895723/

#### CopyOnWrite

CopyOnWrite容器
可以对CopyOnWrite容器进行并发的读，而不需要加锁。CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，不适合需要数据强一致性的场景。

实现读写分离，读取发生在原始数据上，写入发生在副本上。
不用加锁，通过最终一致实现一致性。

> https://www.cnblogs.com/hapjin/p/4840107.html

1，什么是写时复制(Copy-On-Write)容器？
写时复制是指：在并发访问的情景下，当需要修改JAVA中Containers的元素时，不直接修改该容器，而是先复制一份副本，在副本上进行修改。修改完成之后，将指向原来容器的引用指向新的容器(副本容器)。
2，写时复制带来的影响
①由于不会修改原始容器，只修改副本容器。因此，可以对原始容器进行并发地读。其次，实现了读操作与写操作的分离，读操作发生在原始容器上，写操作发生在副本容器上。
②数据一致性问题：读操作的线程可能不会立即读取到新修改的数据，因为修改操作发生在副本上。但最终修改操作会完成并更新容器，因此这是最终一致性。

#### RingBuffer

在程序设计中，我们有时会遇到这样的情况，一个线程将数据写到一个buffer中，另外一个线程从中读数据。所以这里就有多线程竞争的问题。通常的解决办法是对竞争资源加锁。但是，一般加锁的损耗较高。其实，对于这样的一个线程写，一个线程读的特殊情况，可以以一种简单的无锁RingBuffer来实现。这样代码的运行效率很高。
如图所示，假定buffer的长度是bufferSize. 我们设置两个指针。head指向的是下一次读的位置，而tail指向的是下一次写的位置。由于这里是环形buffer (ring buffer)，这里就有一个问题，怎样判断buffer是满或者空。这里采用的规则是，buffer的最后一个单元不存储数据。所以，如果head == tail，那么说明buffer为空。如果 head == tail + 1 (mod bufferSize)，那么说明buffer满了。
接下来就是最重要的内容了：怎样以无锁的方式进行线程安全的buffer的读写操作。基本原理是这样的。在进行读操作的时候，我们只修改head的值，而在写操作的时候我们只修改tail的值。在写操作时，我们在写入内容到buffer之后才修改tail的值；而在进行读操作的时候，我们会读取tail的值并将其赋值给copyTail。赋值操作是原子操作。所以在读到copyTail之后，从head到copyTail之间一定是有数据可以读的，不会出现数据没有写入就进行读操作的情况。同样的，读操作完成之后，才会修改head的数值；而在写操作之前会读取head的值判断是否有空间可以用来写数据。所以，这时候tail到head - 1之间一定是有空间可以写数据的，而不会出现一个位置的数据还没有读出就被写操作覆盖的情况。这样就保证了RingBuffer的线程安全性。

#### 可重入锁 & 不可重入锁

通过简单代码举例说明可重入锁和不可重入锁。
可重入锁指同一个线程可以再次获得之前已经获得的锁。
可重入锁可以用户避免死锁。
Java中的可重入锁：synchronized 和 java.util.concurrent.locks.ReentrantLock
synchronized 使用方便，编译器来加锁，是非公平锁。
ReenTrantLock 使用灵活，锁的公平性可以定制。
相同加锁场景下，推荐使用 synchronized。

#### 互斥锁 & 共享锁
互斥锁：同时只能有一个线程获得锁。比如，ReentrantLock 是互斥锁，ReadWriteLock 中的写锁是互斥锁。
共享锁：可以有多个线程同时或的锁。比如，Semaphore、CountDownLatch 是共享锁，ReadWriteLock 中的读锁是共享锁。

#### 死锁

互斥、持有、不可剥夺、环形等待。

### DevOps

参考最近阅读的小册：
> https://juejin.cn/book/6897616008173846543

### 中间件

#### Nginx

Nginx 通过异步非阻塞的事件处理机制实现高并发。Apache 每个请求独占一个线程，非常消耗系统资源。
事件驱动适合于IO密集型服务(Nginx)，多进程或线程适合于CPU密集型服务(Apache)，所以Nginx适合做反向代理，而非web服务器使用。

#### Jetty&Tomcat

架构比较:Jetty的架构比Tomcat的更为简单。
性能比较：Jetty和Tomcat性能方面差异不大，Jetty默认采用NIO结束在处理I/O请求上更占优势，Tomcat默认采用BIO处理I/O请求，Tomcat适合处理少数非常繁忙的链接，处理静态资源时性能较差。
其他方面：Jetty的应用更加快速，修改简单，对新的Servlet规范的支持较好;Tomcat 对JEE和Servlet 支持更加全面。

### Cache

#### gee-cache

可以参考曾经阅读的实践代码：gee-cache
https://github.com/peigongdh/7days-golang

#### memcached

采用多路复用技术提高并发性。
slab分配算法： memcached给Slab分配内存空间，默认是1MB。分配给Slab之后 把slab的切分成大小相同的chunk，Chunk是用于缓存记录的内存空间，Chunk 的大小默认按照1.25倍的速度递增。好处是不会频繁申请内存，提高IO效率，坏处是会有一定的内存浪费。

#### Redis

使用 ziplist 存储链表，ziplist是一种压缩链表，它的好处是更能节省内存空间，因为它所存储的内容都是在连续的内存区域当中的。
使用 skiplist(跳跃表)来存储有序集合对象、查找上先从高Level查起、时间复杂度和红黑树相当，实现容易，无锁、并发性好。
RDB方式：定期备份快照，常用于灾难恢复。优点：通过fork出的进程进行备份，不影响主进程、RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。缺点：会丢数据。
AOF方式：保存操作日志方式。优点：恢复时数据丢失少，缺点：文件大，回复慢。
也可以两者结合使用。

TODO: 回顾Redis设计的数据结构
> https://blog.csdn.net/wcf373722432/article/details/78678504

#### Tair

特点：可以配置备份节点数目，通过异步同步到备份节点
一致性Hash算法。
架构：和Hadoop 的设计思想类似，有Configserver，DataServer，Configserver 通过心跳来检测，Configserver也有主备关系。
几种存储引擎:

MDB，完全内存性，可以用来存储Session等数据。
Rdb（类似于Redis），轻量化，去除了aof之类的操作，支持Restfull操作
LDB（LevelDB存储引擎），持久化存储，LDB 作为rdb的持久化，google实现，比较高效，理论基础是LSM(Log-Structured-Merge Tree)算法，现在内存中修改数据，达到一定量时（和内存汇总的旧数据一同写入磁盘）再写入磁盘，存储更加高效，县比喻Hash算法。
Tair采用共享内存来存储数据，如果服务挂掉（非服务器），重启服务之后，数据亦然还在。

### 消息队列

RabbitMQ 消费者默认是推模式（也支持拉模式）。
Kafka 默认是拉模式。
Push方式：优点是可以尽可能快地将消息发送给消费者，缺点是如果消费者处理能力跟不上，消费者的缓冲区可能会溢出。
Pull方式：优点是消费端可以按处理能力进行拉去，缺点是会增加消息延迟。

曾经读过的文章，消息队列的设计：
> https://tech.meituan.com/2016/07/01/mq-design.html

#### RabbitMQ

支持事务，推拉模式都是支持、适合需要可靠性消息传输的场景。

#### RocketMQ

Java实现，推拉模式都是支持，吞吐量逊于Kafka。可以保证消息顺序。

#### ActiveMQ

纯Java实现，兼容JMS，可以内嵌于Java应用中。

#### Kafka

高吞吐量、采用拉模式。适合高IO场景，比如日志同步。

#### Redis 消息推送

生产者、消费者模式完全是客户端行为，list 和 拉模式实现，阻塞等待采用 blpop 指令。

### 定时调度

#### 单机定时调度

fork 进程 + sleep 轮询
定时调度在 QuartzSchedulerThread 代码中，while()无限循环，每次循环取出时间将到的trigger，触发对应的job，直到调度器线程被关闭。

#### 分布式定时调度

opencron、LTS、XXL-JOB、Elastic-Job、Uncode-Schedule、Antares
Quartz集群中，独立的Quartz节点并不与另一其的节点或是管理节点通信，而是通过相同的数据库表来感知到另一Quartz应用的

### RPC

Dubbo
Thrift
gRPC

### 配置中心

TODO: 对比QTT的全局配置平台实现

#### apollo

Apollo（阿波罗）是携程框架部门研发的开源配置管理中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性。
Apollo支持4个维度管理Key-Value格式的配置：

application (应用)
environment (环境)
cluster (集群)
namespace (命名空间)
同时，Apollo基于开源模式开发，开源地址：https://github.com/ctripcorp/apollo

### API网关

主要职责：请求转发、安全认证、协议转换、容灾。

> https://www.infoq.cn/article/2016/07/API-background-architecture-floo/

摘录：
Netflix 其实并没有对 API GW 进行深入的功能实现（或者说面相业务友好的相关功能），整体上它只提供了一个技术框架、和一些标准的 filter 实例实现，相信了解过 filter chain 原理的分布式中间件工程师也能搭出这样的框架。这么做的原因，我认为很大原因是 API GW 所扮演的角色是一个业务平台，而非技术平台，将行业特征很强的业务部分开源，对于受众意义也不是特别大。另外，除了 Netflix Zuul，在商业产品上还有 apigee 公司所提供的方案，在轻量级开源实现上还有基于 Nginx 的 kong ，kong 其实提供了 19 个插件式的功能实现，涵盖的面主要在于安全、监控等领域，但缺少对报文转换的能力（为什么缺 也很显而易见——避免产生业务场景的耦合，更通用）。

API GW 本身

NIO 接入，异步接出
流控与屏蔽
秘钥交换
客户端认证与报文加解密
业务路由框架
报文转换
HTTP DNS/ Direct IP
API GW 客户端 SDK / Library

基本通信
秘钥交换与 Cache
身份认证与报文加解密
配套的在线自助服务平台

代码生成
文档生成
沙盒调测

### 网络

#### HTTP&HTTP2.0

参考http2-node-1.md

#### 网络模型

SELECT & POLL & EPOLL

select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的。
select 有打开文件描述符数量限制，默认1024（2048 for x64），100万并发，就要用1000个进程、切换开销大；poll采用链表结构，没有数量限制。
select，poll “醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，通过回调机制节省大量CPU时间；select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，而epoll只要一次拷贝。
poll会随着并发增加，性能逐渐下降，epoll采用红黑树结构，性能稳定，不会随着连接数增加而降低。

在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。

#### 序列化

Hessian

Protobuf

### 数据库

**重点**

#### 基础理论

第一范式：数据表中的每一列（每个字段）必须是不可拆分的最小单元，也就是确保每一列的原子性；
第二范式（2NF）：满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情；
第三范式：必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）；

#### NoSQL

MongoDB
优点：弱一致性（最终一致），更能保证用户的访问速度；内置GridFS，支持大容量的存储；Schema-less 数据库，不用预先定义结构；内置Sharding；相比于其他NoSQL，第三方支持丰富；性能优越；
缺点：mongodb不支持事务操作；mongodb占用空间过大；MongoDB没有如MySQL那样成熟的维护工具，这对于开发和IT运营都是个值得注意的地方；

Hbase
空数据不存储，节省空间，且适用于并发。
rowkey 按照字典顺序排列，便于批量扫描。
通过散列可以避免热点。

### 搜索引擎

Lucene
Elasticsearch
Solr

### 大数据

流式计算

Storm
Flink
Kafka Stream

应用场景：

广告相关实时统计；
推荐系统用户画像标签实时更新；
线上服务健康状况实时监测；
实时榜单；
实时数据统计。

### 安全

XSS
CSRF
SQL 注入
Hash Dos
脚本注入
漏洞扫描工具
验证码
DDoS 防范
用户隐私信息保护

#### 鉴权

授权、认证
RBAC
OAuth2.0
单点登录(SSO)

### 分布式设计

#### 扩展性设计

总结下来，通用的套路就是分布、缓存及异步处理。
水平切分+垂直切分
利用中间件进行分片如，MySQL Proxy。
利用分片策略进行切分，如按照ID取模。
分布式服务+消息队列。

#### 稳定性 & 高可用

可扩展：水平扩展、垂直扩展。 通过冗余部署，避免单点故障。
隔离：避免单一业务占用全部资源。避免业务之间的相互影响 2. 机房隔离避免单点故障。
解耦：降低维护成本，降低耦合风险。减少依赖，减少相互间的影响。
限流：滑动窗口计数法、漏桶算法、令牌桶算法等算法。遇到突发流量时，保证系统稳定。
降级：紧急情况下释放非核心功能的资源。牺牲非核心业务，保证核心业务的高可用。
熔断：异常情况超出阈值进入熔断状态，快速失败。减少不稳定的外部依赖对核心服务的影响。
自动化测试：通过完善的测试，减少发布引起的故障。
灰度发布：灰度发布是速度与安全性作为妥协，能够有效减少发布故障。
设计原则：数据不丢(持久化)；服务高可用(服务副本)；绝对的100%高可用很难，目标是做到尽可能多的9，如99.999%（全年累计只有5分钟）。

#### 硬件负载均衡

#### 软件负载均衡

《几种负载均衡算法》 轮寻、权重、负载、最少连接、QoS

《DNS负载均衡》

配置简单，更新速度慢。
《Nginx负载均衡》

简单轻量、学习成本低；主要适用于web应用。
《借助LVS+Keepalived实现负载均衡 》

配置比较负载、只支持到4层，性能较高。
《HAProxy用法详解 全网最详细中文文档》

支持到七层（比如HTTP）、功能比较全面，性能也不错。
《Haproxy+Keepalived+MySQL实现读均衡负载》

主要是用户读请求的负载均衡。
《rabbitmq+haproxy+keepalived实现高可用集群搭建》

#### 限流

计数器：通过滑动窗口计数器，控制单位时间内的请求次数，简单粗暴。
漏桶算法：固定容量的漏桶，漏桶满了就丢弃请求，比较常用。
令牌桶算法：固定容量的令牌桶，按照一定速率添加令牌，处理请求前需要拿到令牌，拿不到令牌则丢弃请求，或进入丢队列，可以通过控制添加令牌的速率，来控制整体速度。Guava 中的 RateLimiter 是令牌桶的实现。
Nginx 限流：通过 limit_req 等模块限制并发连接数。

#### 应用层容灾

雪崩效应原因：硬件故障、硬件故障、程序Bug、重试加大流量、用户大量请求。
雪崩的对策：限流、改进缓存模式(缓存预加载、同步调用改异步)、自动扩容、降级。
Hystrix设计原则：
资源隔离：Hystrix通过将每个依赖服务分配独立的线程池进行资源隔离, 从而避免服务雪崩。
熔断开关：服务的健康状况 = 请求失败数 / 请求总数，通过阈值设定和滑动窗口控制开关。
命令模式：通过继承 HystrixCommand 来包装服务调用逻辑。

主要策略：失效瞬间：单机使用锁；使用分布式锁；不过期；
热点数据：热点数据单独存储；使用本地缓存；分成多个子key；

考虑singleFight
防缓存击穿的方式有很多种，比如通过计划任务来跟新缓存使得从前端过来的所有请求都是从缓存读取等等。之前读过 groupCache的源码，发现里面有一个很有意思的库，叫singleFlight, 因为groupCache从节点上获取缓存如果未命中，则会去其他节点寻找，其他节点还没有的话再从数据源获取，所以这个步骤对于防击穿非常有必要。singleFlight使得groupCache在多个并发请求对一个失效的key进行源数据获取时，只让其中一个得到执行，其余阻塞等待到执行的那个请求完成后，将结果传递给阻塞的其他请求达到防止击穿的效果。

对比学习过的gee-cache中的单飞模型

缓存雪崩：缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。缓存雪崩通常因为缓存服务器宕机、缓存的 key 设置了相同的过期时间等引起。设置固定+随机的过期时间
缓存击穿：一个存在的key，在缓存过期的一刻，同时有大量的请求，这些请求都会击穿到 DB ，造成瞬时DB请求量大、压力骤增。 使用singleFight
缓存穿透：查询一个不存在的数据，因为不存在则不会写到缓存中，所以每次都会去请求 DB，如果瞬间流量过大，穿透到 DB，导致宕机。为空结果集设置缓存

#### 跨机房容灾

通过自研中间件进行数据同步。
注意延迟问题，多次跨机房调用会将延时放大数倍。
建房间专线很大概率会出现问题，做好运维和程序层面的容错。
不能依赖于程序端数据双写，要有自动同步方案。
数据永不在高延迟和较差网络质量下，考虑同步质量问题。
核心业务和次要业务分而治之，甚至只考虑核心业务。
异地多活监控部署、测试也要跟上。
业务允许的情况下考虑用户分区，尤其是游戏、邮箱业务。
控制跨机房消息体大小，越小越好。
考虑使用docker容器虚拟化技术，提高动态调度能力。

#### 容灾演练流程

常见故障画像
案例：预案有效性、预案有效性、故障复现、架构容灾测试、参数调优、参数调优、故障突袭、联合演练。

平滑启动
平滑重启应用思路 1.端流量（如vip层）、2. flush 数据(如果有)、3, 重启应用
《JVM安全退出（如何优雅的关闭java服务）》 推荐推出方式：System.exit，Kill SIGTERM；不推荐 kill-9；用 Runtime.addShutdownHook 注册钩子。
《常见Java应用如何优雅关闭》 Java、Spring、Dubbo 优雅关闭方式。

参考整理的笔记：hot-start-node-1.md

### 数据库扩展

#### 分片模式

中间件： 轻量级：sharding-jdbc、TSharding；重量级：Atlas、MyCAT、Vitess等。
问题：事务、Join、迁移、扩容、ID、分页等。
事务补偿：对数据进行对帐检查;基于日志进行比对;定期同标准数据来源进行同步等。
分库策略：数值范围；取模；日期等。
分库数量：通常 MySQL 单库 5千万条、Oracle 单库一亿条需要分库。
分区：是MySQL内部机制，对客户端透明，数据存储在不同文件中，表面上看是同一个表。
分表：物理上创建不同的表、客户端需要管理分表路由。

#### 服务发现

**重点**

客户端服务发现模式：客户端直接查询注册表，同时自己负责负载均衡。Eureka 采用这种方式。
服务器端服务发现模式：客户端通过负载均衡查询服务实例。
CAP支持：Consul（CA）、zookeeper（cp）、etcd（cp） 、euerka（ap）
产品设计中 CAP 理论的取舍
Eureka 典型的 AP,作为分布式场景下的服务发现的产品较为合适，服务发现场景的可用性优先级较高，一致
性并不是特别致命。其次 CA 类型的场景 Consul,也能提供较高的可用性，并能 k-v store 服务保证一致性。 
而Zookeeper,Etcd则是CP类型 牺牲可用性，在服务发现场景并没太大优势；

#### 服务路由控制

原则：透明化路由
负载均衡策略：随机、轮询、服务调用延迟、一致性哈希、粘滞连接
本地路由优先策略：injvm(优先调用jvm内部的服务)，innative(优先使用相同物理机的服务),原则上找距离最近的服务。
配置方式：统一注册表；本地配置；动态下发。

#### CAP

> https://www.cnblogs.com/szlbm/p/5588543.html

1、有些系统，既要快速地响应用户，同时还要保证系统的数据对于任意客户端都是真实可靠的，就像火车站售票系统
2、有些系统，需要为用户保证绝对可靠的数据安全，虽然在数据一致性上存在延时，但最终务必保证严格的一致性，就像银行的转账系统
3、有些系统，虽然向用户展示了一些可以说是"错误"的数据，但是在整个系统使用过程中，一定会在某一个流程上对系统数据进行准确无误的检查，从而避免用户发生不必要的损失，就像网购系统

分布一致性的提出
在分布式系统中要解决的一个重要问题就是数据的复制。在我们的日常开发经验中，相 信很多开发人员都遇到过这样的问题：假设客户端C1将系统中的一个值K由V1更新为V2，但客户端C2无法立即读取到K的最新值，需要在一段时间之后才能 读取到。这很正常，因为数据库复制之间存在延时。

分布式系统对于数据的复制需求一般都来自于以下两个原因：
1、为了增加系统的可用性，以防止单点故障引起的系统不可用
2、提高系统的整体性能，通过负载均衡技术，能够让分布在不同地方的数据副本都能够为用户提供服务

数据复制在可用性和性能方面给分布式系统带来的巨大好处是不言而喻的，然而数据复制所带来的一致性挑战，也是每一个系统研发人员不得不面对的。
所谓分布一致性问题，是指在分布式环境中引入数据复制机制之后，不同数据节点之间 可能出现的，并无法依靠计算机应用程序自身解决的数据不一致的情况。简单讲，数据一致性就是指在对一个副本数据进行更新的时候，必须确保也能够更新其他的 副本，否则不同副本之间的数据将不一致。
那么如何解决这个问题？一种思路是"既然是由于延时动作引起的问题，那我可以将写入的动作阻塞，直到数据复制完成后，才完成写入动作"。 没错，这似乎能解决问题，而且有一些系统的架构也确实直接使用了这个思路。但这个思路在解决一致性问题的同时，又带来了新的问题：写入的性能。如果你的应 用场景有非常多的写请求，那么使用这个思路之后，后续的写请求都将会阻塞在前一个请求的写操作上，导致系统整体性能急剧下降。

总得来说，我们无法找到一种能够满足分布式系统所有系统属性的分布式一致性解决方案。因此，如何既保证数据的一致性，同时又不影响系统运行的性能，是每一个分布式系统都需要重点考虑和权衡的。于是，一致性级别由此诞生：
1、强一致性
这种一致性级别是最符合用户直觉的，它要求系统写入什么，读出来的也会是什么，用户体验好，但实现起来往往对系统的性能影响大
2、弱一致性
这种一致性级别约束了系统在写入成功后，不承诺立即可以读到写入的值，也不久承诺多久之后数据能够达到一致，但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态
3、最终一致性
最终一致性是弱一致性的一个特例，系统会保证在一定时间内，能够达到一个数据一致的状态。这里之所以将最终一致性单独提出来，是因为它是弱一致性中非常推崇的一种一致性模型，也是业界在大型分布式系统的数据一致性上比较推崇的模型

CAP理论
一个经典的分布式系统理论。CAP理论告诉我们：一个分布式系统不可能同时满足一致性（C：Consistency）、可用性（A：Availability）和分区容错性（P：Partition tolerance）这三个基本需求，最多只能同时满足其中两项。

1、一致性
在分布式环境下，一致性是指数据在多个副本之间能否保持一致的特性。在一致性的需求下，当一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一直的状态。
对于一个将数据副本分布在不同分布式节点上的系统来说，如果对第一个节点的数据进 行了更新操作并且更新成功后，却没有使得第二个节点上的数据得到相应的更新，于是在对第二个节点的数据进行读取操作时，获取的依然是老数据（或称为脏数 据），这就是典型的分布式数据不一致的情况。在分布式系统中，如果能够做到针对一个数据项的更新操作执行成功后，所有的用户都可以读取到其最新的值，那么 这样的系统就被认为具有强一致性

2、可用性
可用性是指系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。这里的重点是"有限时间内"和"返回结果"。
"有限时间内"是指，对于用户的一个操作请求，系统必须能够在指定的时间内返回对 应的处理结果，如果超过了这个时间范围，那么系统就被认为是不可用的。另外，"有限的时间内"是指系统设计之初就设计好的运行指标，通常不同系统之间有很 大的不同，无论如何，对于用户请求，系统必须存在一个合理的响应时间，否则用户便会对系统感到失望。
"返回结果"是可用性的另一个非常重要的指标，它要求系统在完成对用户请求的处理后，返回一个正常的响应结果。正常的响应结果通常能够明确地反映出队请求的处理结果，即成功或失败，而不是一个让用户感到困惑的返回结果。

3、分区容错性
分区容错性约束了一个分布式系统具有如下特性：分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障。
网络分区是指在分布式系统中，不同的节点分布在不同的子网络（机房或异地网络） 中，由于一些特殊的原因导致这些子网络出现网络不连通的状况，但各个子网络的内部网络是正常的，从而导致整个系统的网络环境被切分成了若干个孤立的区域。 需要注意的是，组成一个分布式系统的每个节点的加入与退出都可以看作是一个特殊的网络分区。

既然一个分布式系统无法同时满足一致性、可用性、分区容错性三个特点，所以我们就需要抛弃一样：
CA	放弃分区容错性，加强一致性和可用性，其实就是传统的单机数据库的选择
AP	放弃一致性（这里说的一致性是强一致性），追求分区容错性和可用性，这是很多分布式系统设计时的选择，例如很多NoSQL系统就是如此
CP	放弃可用性，追求一致性和分区容错性，基本不会选择，网络问题会直接让整个系统不可用

需要明确的一点是，对于一个分布式系统而言，分区容错性是一个最基本的要求。因为 既然是一个分布式系统，那么分布式系统中的组件必然需要被部署到不同的节点，否则也就无所谓分布式系统了，因此必然出现子网络。而对于分布式系统而言，网 络问题又是一个必定会出现的异常情况，因此分区容错性也就成为了一个分布式系统必然需要面对和解决的问题。因此系统架构师往往需要把精力花在如何根据业务 特点在C（一致性）和A（可用性）之间寻求平衡。

BASE理论

BASE是Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）三个短语的缩写。BASE理论是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的总结， 是基于CAP定理逐步演化而来的。BASE理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。接下来看一下BASE中的三要素：

1、基本可用
基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性----注意，这绝不等价于系统不可用。比如：
（1）响应时间上的损失。正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障，查询结果的响应时间增加了1~2秒
（2）系统功能上的损失：正常情况下，在一个电子商务网站上进行购物的时候，消费者几乎能够顺利完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面

2、软状态
软状态指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时

3、最终一致性
最终一致性强调的是所有的数据副本，在经过一段时间的同步之后，最终都能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。
总的来说，BASE理论面向的是大型高可用可扩展的分布式系统，和传统的事物ACID特性是相反的，它完全不同于ACID的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。但同时，在实际的分布式场景中，不同业务单元和组件对数据一致性的要求是不同的，因此在具体的分布式系统架构设计过程中，ACID特性和BASE理论往往又会结合在一起。

#### 分布式锁

基于数据库的分布式锁：优点：操作简单、容易理解。缺点：存在单点问题、数据库性能够开销较大、不可重入；
基于缓存的分布式锁：优点：非阻塞、性能好。缺点：操作不好容易造成锁无法释放的情况。
Zookeeper 分布式锁：通过有序临时节点实现锁机制，自己对应的节点需要最小，则被认为是获得了锁。优点：集群可以透明解决单点问题，避免锁不被释放问题，同时锁可以重入。缺点：性能不如缓存方式，吞吐量会随着zk集群规模变大而下降。

Redis-分布式锁
基于 setnx(set if ont exists)，有则返回false，否则返回true。并支持过期时间。

#### 分布式一致性算法

PAXOS

Raft
三种角色：Leader（领袖）、Follower（群众）、Candidate（候选人）
通过随机等待的方式发出投票，得票多的获胜。

通过回顾算法：https://km.qutoutiao.net/pages/viewpage.action?pageId=222068805

Gossip
《Gossip算法》

#### 幂等

幂等特性的作用：该资源具备幂等性，请求方无需担心重复调用会产生错误。
常见保证幂等的手段：MVCC（类似于乐观锁）、去重表(唯一索引)、悲观锁、一次性token、序列号方式。

#### 分布式一致方案

TCC(Try/Confirm/Cancel) 柔性事务
基于BASE理论：基本可用、柔性状态、最终一致。
解决方案：记录日志+补偿（正向补充或者回滚）、消息重试(要求程序要幂等)；“无锁设计”、采用乐观锁机制。

#### 唯一ID 生成

Twitter 方案（Snowflake 算法）：41位时间戳+10位机器标识（比如IP，服务器名称等）+12位序列号(本地计数器)
Flicker 方案：MySQL自增ID + "REPLACE INTO XXX:SELECT LAST_INSERT_ID();"
UUID：缺点，无序，字符串过长，占用空间，影响检索性能。
MongoDB 方案：利用 ObjectId。缺点：不能自增。

在数据库中创建 sequence 表，用于记录，当前已被占用的id最大值。
每台客户端主机取一个id区间（比如 1000~2000）缓存在本地，并更新 sequence 表中的id最大值记录。
客户端主机之间取不同的id区间，用完再取，使用乐观锁机制控制并发。

#### 一致哈希

> https://coderxing.gitbooks.io/architecture-evolution/content/di-san-pian-ff1a-bu-luo/631-yi-zhi-xing-ha-xi.html

​ 一致性哈希（Consistent hashing）算法是由 MIT 的Karger 等人与1997年在一篇学术论文（《Consistent hashing and random trees: distributed caching protocols for relieving hot spots on the World Wide Web》）中提出来的，用于解决分布式缓存数据分布问题。在传统的哈希算法下，每条缓存数据落在那个节点是通过哈希算法和服务器节点数量计算出来的，一旦服务器节点数量发生增加或者介绍，哈希值需要重新计算，此时几乎所有的数据和服务器节点的对应关系也会随之发生变化，进而会造成绝大多数缓存的失效。一致性哈希算法通过环形结构和虚拟节点的概念，确保了在缓存服务器节点数量发生变化时大部分数据保持原地不动，从而大幅提高了缓存的有效性。下面我们通过例子来解释一致性哈希的原理。

